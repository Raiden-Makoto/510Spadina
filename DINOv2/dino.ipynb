{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73f16478",
   "metadata": {},
   "source": [
    "## A more accurate Human to Anime Feature Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f412ed32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import clip\n",
    "import glob\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "439b9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "model = timm.create_model(\"vit_base_patch14_dinov2.lvd142m\", pretrained=True)\n",
    "model = model.eval().to(device)\n",
    "clip_model, preprocess_clip = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5a65d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((518, 518)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86e29fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dino_embedding(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        emb = model.forward_features(x)  # feature extraction\n",
    "    return emb.cpu().numpy().flatten()\n",
    "\n",
    "def get_clip_embedding(img_path):\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_pre = preprocess_clip(img).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        return clip_model.encode_image(img_pre).cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f42ec2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all PNG and JPG files from GenshinCharacters directory\n",
    "avatar_files = glob.glob(\"../GenshinCharacters/*.png\") + glob.glob(\"../GenshinCharacters/*.jpg\")\n",
    "dino_embeddings = [get_dino_embedding(img) for img in avatar_files]\n",
    "clip_embeddings = [get_clip_embedding(img) for img in avatar_files]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b9fca9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = os.environ[\"TEST_IMG_PATH\"]\n",
    "query_dino_emb = get_dino_embedding(test_path)\n",
    "query_clip_emb = get_clip_embedding(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "580049f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_similarity(q_dino, q_clip, a_dino, a_clip, alpha=0.67):\n",
    "    # normalize\n",
    "    q_dino /= np.linalg.norm(q_dino)\n",
    "    q_clip /= np.linalg.norm(q_clip)\n",
    "    a_dino /= np.linalg.norm(a_dino)\n",
    "    a_clip /= np.linalg.norm(a_clip)\n",
    "    \n",
    "    sim_dino = np.dot(q_dino, a_dino)\n",
    "    sim_clip = np.dot(q_clip, a_clip)\n",
    "    return alpha*sim_clip + (1-alpha)*sim_dino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "71439164",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = [combined_similarity(query_dino_emb, query_clip_emb, emb[0], emb[1]) for emb in zip(dino_embeddings, clip_embeddings)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0669c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best match: ../GenshinCharacters/Fischl.png \n",
      "Score: 0.43704224\n"
     ]
    }
   ],
   "source": [
    "best_idx = int(np.argmax(similarities))\n",
    "print(\"Best match:\", avatar_files[best_idx], \"\\nScore:\", similarities[best_idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
